{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "from scipy.optimize import linprog, minimize\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Utilities\n",
    "# --------------------------\n",
    "\n",
    "def all_bitstrings(n: int) -> np.ndarray:\n",
    "    return np.array(list(itertools.product([0, 1], repeat=n)), dtype=int)\n",
    "\n",
    "\n",
    "def all_branches(n: int, h: int) -> List[Tuple[Tuple[int, ...], Tuple[int, ...]]]:\n",
    "    k = n - h\n",
    "    branches = []\n",
    "    for A in itertools.combinations(range(n), k):\n",
    "        for aA in itertools.product([0, 1], repeat=k):\n",
    "            branches.append((tuple(A), tuple(aA)))\n",
    "    return branches\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -40, 40)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sort_desc(s: np.ndarray) -> np.ndarray:\n",
    "    return np.sort(np.asarray(s, dtype=float))[::-1]\n",
    "\n",
    "\n",
    "def linprog_any(c, A_ub, b_ub, A_eq, b_eq, bounds):\n",
    "    methods = (\"highs\", \"highs-ds\", \"highs-ipm\", \"interior-point\", \"revised simplex\", \"simplex\")\n",
    "    last_err = None\n",
    "    for method in methods:\n",
    "        try:\n",
    "            return linprog(\n",
    "                c=c, A_ub=A_ub, b_ub=b_ub,\n",
    "                A_eq=A_eq, b_eq=b_eq,\n",
    "                bounds=bounds,\n",
    "                method=method\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err is not None:\n",
    "        raise last_err\n",
    "    raise RuntimeError(\"linprog failed unexpectedly.\")\n",
    "\n",
    "\n",
    "def cache_key_from_s(s: np.ndarray, *, tol: float = 1e-4) -> tuple:\n",
    "    s = np.clip(np.asarray(s, dtype=float), 0.0, 1.0)\n",
    "    q = np.round(s / tol).astype(np.int64)\n",
    "    diffs = np.diff(q)\n",
    "    return (int(q[0]), *map(int, diffs))\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Inner LP solver\n",
    "# --------------------------\n",
    "\n",
    "@dataclass\n",
    "class LPValue:\n",
    "    ok: bool\n",
    "    t: float\n",
    "    f: Optional[np.ndarray]\n",
    "    msg: str\n",
    "\n",
    "\n",
    "class FullProgramLPSolver:\n",
    "    \"\"\"\n",
    "    Fixes the build_ub bottleneck:\n",
    "      - precompute A_ub CSR structure ONCE\n",
    "      - per solve, only fill COO-order data vector then permute into CSR-order data\n",
    "      - reuse indices/indptr (no COO->CSR conversion per miss)\n",
    "\n",
    "    Also uses cheap weight computation from term = where(bits, s, 1-s):\n",
    "      - pi = prod(term, axis=1)\n",
    "      - eq weights: w_i = pi / term[:, i]\n",
    "      - branch weights: w_A = prod(term[:, comp(A)], axis=1)   where comp(A) has size h\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n: int,\n",
    "        h: int,\n",
    "        C: float,\n",
    "        cache_tol: float = 1e-4,\n",
    "        cache_max: int = 200_000,\n",
    "        profile: bool = True,\n",
    "    ):\n",
    "        self.n = int(n)\n",
    "        self.h = int(h)\n",
    "        self.C = float(C)\n",
    "\n",
    "        self.bits = all_bitstrings(self.n)  # (m,n)\n",
    "        self.m = self.bits.shape[0]\n",
    "        self.all_zero = (self.bits.sum(axis=1) == 0).astype(float)  # (m,)\n",
    "\n",
    "        self.branches = all_branches(self.n, self.h)\n",
    "        self.num_branches = len(self.branches)\n",
    "\n",
    "        # Variable layout\n",
    "        self.N = self.n * self.m + 1\n",
    "        self.t_idx = self.n * self.m\n",
    "        self.bounds = [(0.0, None)] * (self.n * self.m) + [(0.0, None)]\n",
    "        self.c = np.zeros(self.N, dtype=float)\n",
    "        self.c[self.t_idx] = 1.0\n",
    "\n",
    "        # Precompute eq index sets\n",
    "        self.eq_idx1 = [np.where(self.bits[:, i] == 1)[0] for i in range(self.n)]\n",
    "        self.eq_idx0 = [np.where(self.bits[:, i] == 0)[0] for i in range(self.n)]\n",
    "        self.eq_cols1 = [i * self.m + self.eq_idx1[i] for i in range(self.n)]\n",
    "        self.eq_cols0 = [i * self.m + self.eq_idx0[i] for i in range(self.n)]\n",
    "\n",
    "        # Branch precompute:\n",
    "        # - idx of a matching (A,aA)\n",
    "        # - comp(A) columns (size h)\n",
    "        # - whether idx contains 0 (all-zero bitstring, which is row 0)\n",
    "        all_idx = np.arange(self.n)\n",
    "        self.branch_match_idx: List[np.ndarray] = []\n",
    "        self.branch_cols_per_i: List[List[np.ndarray]] = []\n",
    "        self.branch_comp_cols: List[np.ndarray] = []\n",
    "        self.branch_has_zero = np.zeros(self.num_branches, dtype=bool)\n",
    "\n",
    "        for b, (A, aA) in enumerate(self.branches):\n",
    "            mask = np.ones(self.m, dtype=bool)\n",
    "            for pos, j in enumerate(A):\n",
    "                mask &= (self.bits[:, j] == aA[pos])\n",
    "            idx = np.where(mask)[0]\n",
    "            self.branch_match_idx.append(idx)\n",
    "            self.branch_cols_per_i.append([i * self.m + idx for i in range(self.n)])\n",
    "\n",
    "            Aset = set(A)\n",
    "            comp = np.array([j for j in all_idx if j not in Aset], dtype=int)  # size h\n",
    "            self.branch_comp_cols.append(comp)\n",
    "\n",
    "            self.branch_has_zero[b] = (idx.size > 0 and idx[0] == 0) or (0 in set(idx.tolist()))\n",
    "\n",
    "        # ----------------------\n",
    "        # Precompute A_ub pattern in COO order (rows, cols) + slices\n",
    "        # ----------------------\n",
    "        self.num_ub = 1 + self.num_branches\n",
    "\n",
    "        total_nnz = self.n * self.m\n",
    "        for idx in self.branch_match_idx:\n",
    "            total_nnz += self.n * idx.size + 1\n",
    "\n",
    "        self._ub_rows = np.empty(total_nnz, dtype=int)\n",
    "        self._ub_cols = np.empty(total_nnz, dtype=int)\n",
    "\n",
    "        self._ir_slices: List[slice] = []\n",
    "        self._branch_slices: List[List[slice]] = []\n",
    "        self._t_pos = np.empty(self.num_branches, dtype=int)\n",
    "\n",
    "        off = 0\n",
    "        # IR row pattern (row 0)\n",
    "        for i in range(self.n):\n",
    "            cols = i * self.m + np.arange(self.m, dtype=int)\n",
    "            self._ub_rows[off:off + self.m] = 0\n",
    "            self._ub_cols[off:off + self.m] = cols\n",
    "            self._ir_slices.append(slice(off, off + self.m))\n",
    "            off += self.m\n",
    "\n",
    "        # Branch row patterns\n",
    "        for b in range(self.num_branches):\n",
    "            row = 1 + b\n",
    "            idx = self.branch_match_idx[b]\n",
    "            b_slices = []\n",
    "            for i in range(self.n):\n",
    "                cols = self.branch_cols_per_i[b][i]\n",
    "                L = cols.size\n",
    "                self._ub_rows[off:off + L] = row\n",
    "                self._ub_cols[off:off + L] = cols\n",
    "                b_slices.append(slice(off, off + L))\n",
    "                off += L\n",
    "\n",
    "            # -t entry\n",
    "            self._ub_rows[off] = row\n",
    "            self._ub_cols[off] = self.t_idx\n",
    "            self._t_pos[b] = off\n",
    "            off += 1\n",
    "            self._branch_slices.append(b_slices)\n",
    "\n",
    "        assert off == total_nnz\n",
    "\n",
    "        # ----------------------\n",
    "        # Build CSR template ONCE + permutation mapping COO-order -> CSR-order\n",
    "        # Trick: put data = 0..nnz-1, convert to CSR, then csr.data are those ids in CSR order.\n",
    "        # ----------------------\n",
    "        ids = np.arange(total_nnz, dtype=float)\n",
    "        csr_template = coo_matrix((ids, (self._ub_rows, self._ub_cols)),\n",
    "                                  shape=(self.num_ub, self.N)).tocsr()\n",
    "\n",
    "        # perm[k] = which COO entry sits at CSR position k\n",
    "        self._ub_perm = csr_template.data.astype(np.int64)\n",
    "        self._ub_indices = csr_template.indices.copy()\n",
    "        self._ub_indptr = csr_template.indptr.copy()\n",
    "\n",
    "        # A_eq is tiny; keep building it per miss (it wasn't your bottleneck)\n",
    "\n",
    "        # Cache\n",
    "        self.cache_tol = float(cache_tol)\n",
    "        self._cache: dict[tuple, LPValue] = {}\n",
    "        self._cache_max = int(cache_max)\n",
    "\n",
    "        # Profiling\n",
    "        self.profile = bool(profile)\n",
    "        self._prof = {\n",
    "            \"calls\": 0,\n",
    "            \"cache_hits\": 0,\n",
    "            \"build_eq_s\": 0.0,\n",
    "            \"build_ub_s\": 0.0,\n",
    "            \"linprog_s\": 0.0,\n",
    "            \"total_s\": 0.0,\n",
    "        }\n",
    "\n",
    "    def solve_lp(self, s: np.ndarray, return_f: bool = False) -> LPValue:\n",
    "        import time\n",
    "        t0 = time.perf_counter()\n",
    "        if self.profile:\n",
    "            self._prof[\"calls\"] += 1\n",
    "\n",
    "        s = np.clip(np.asarray(s, dtype=float), 0.0, 1.0)\n",
    "\n",
    "        key = cache_key_from_s(s, tol=self.cache_tol)\n",
    "        cached = self._cache.get(key)\n",
    "        if cached is not None and ((not return_f) or (cached.f is not None)):\n",
    "            if self.profile:\n",
    "                self._prof[\"cache_hits\"] += 1\n",
    "                self._prof[\"total_s\"] += time.perf_counter() - t0\n",
    "            return cached\n",
    "\n",
    "        n, m, C = self.n, self.m, self.C\n",
    "        N = self.N\n",
    "\n",
    "        # Precompute term + pi once\n",
    "        s_safe = np.clip(s, 1e-12, 1 - 1e-12)\n",
    "        term = np.where(self.bits == 1, s_safe[None, :], (1.0 - s_safe)[None, :])  # (m,n)\n",
    "        pi = term.prod(axis=1)  # (m,)\n",
    "\n",
    "        # ----------------------\n",
    "        # Build A_eq (sparse)\n",
    "        # ----------------------\n",
    "        t_eq0 = time.perf_counter()\n",
    "        eq_rows = []\n",
    "        eq_cols = []\n",
    "        eq_data = []\n",
    "\n",
    "        for i in range(n):\n",
    "            w_i = pi / term[:, i]\n",
    "            idx1 = self.eq_idx1[i]\n",
    "            idx0 = self.eq_idx0[i]\n",
    "            cols1 = self.eq_cols1[i]\n",
    "            cols0 = self.eq_cols0[i]\n",
    "\n",
    "            eq_rows.append(np.full(cols1.shape[0], i, dtype=int))\n",
    "            eq_cols.append(cols1.astype(int))\n",
    "            eq_data.append(w_i[idx1])\n",
    "\n",
    "            eq_rows.append(np.full(cols0.shape[0], i, dtype=int))\n",
    "            eq_cols.append(cols0.astype(int))\n",
    "            eq_data.append(-w_i[idx0])\n",
    "\n",
    "        A_eq = coo_matrix(\n",
    "            (np.concatenate(eq_data), (np.concatenate(eq_rows), np.concatenate(eq_cols))),\n",
    "            shape=(n, N),\n",
    "        ).tocsr()\n",
    "        b_eq = np.ones(n, dtype=float)\n",
    "\n",
    "        if self.profile:\n",
    "            self._prof[\"build_eq_s\"] += time.perf_counter() - t_eq0\n",
    "\n",
    "        # ----------------------\n",
    "        # Build A_ub by ONLY filling data (no COO->CSR conversion)\n",
    "        # ----------------------\n",
    "        t_ub0 = time.perf_counter()\n",
    "\n",
    "        data_coo = np.empty_like(self._ub_rows, dtype=float)\n",
    "        b_ub = np.zeros(self.num_ub, dtype=float)\n",
    "\n",
    "        # IR row blocks: fill -pi\n",
    "        for sl in self._ir_slices:\n",
    "            data_coo[sl] = -pi\n",
    "        b_ub[0] = -float(s.sum())\n",
    "\n",
    "        # Branch rows\n",
    "        for b in range(self.num_branches):\n",
    "            comp = self.branch_comp_cols[b]  # size h\n",
    "            if comp.size == 0:\n",
    "                w = np.ones(m, dtype=float)\n",
    "            else:\n",
    "                w = term[:, comp].prod(axis=1)  # (m,)\n",
    "\n",
    "            idx = self.branch_match_idx[b]\n",
    "            w_idx = w[idx]\n",
    "\n",
    "            for i in range(n):\n",
    "                data_coo[self._branch_slices[b][i]] = w_idx\n",
    "\n",
    "            data_coo[self._t_pos[b]] = -1.0\n",
    "\n",
    "            # RHS constant uses only the all-zero assignment (bitstring 000...0 is index 0)\n",
    "            if self.branch_has_zero[b]:\n",
    "                b_ub[1 + b] = -C * float(w[0])\n",
    "            else:\n",
    "                b_ub[1 + b] = 0.0\n",
    "\n",
    "        # Reorder data into CSR order using perm computed once\n",
    "        data_csr = data_coo[self._ub_perm]\n",
    "\n",
    "        A_ub = csr_matrix((data_csr, self._ub_indices, self._ub_indptr), shape=(self.num_ub, self.N))\n",
    "\n",
    "        if self.profile:\n",
    "            self._prof[\"build_ub_s\"] += time.perf_counter() - t_ub0\n",
    "\n",
    "        # ----------------------\n",
    "        # Solve LP\n",
    "        # ----------------------\n",
    "        t_lp0 = time.perf_counter()\n",
    "        res = linprog_any(self.c, A_ub, b_ub, A_eq, b_eq, self.bounds)\n",
    "        if self.profile:\n",
    "            self._prof[\"linprog_s\"] += time.perf_counter() - t_lp0\n",
    "\n",
    "        if not res.success:\n",
    "            val = LPValue(ok=False, t=float(\"inf\"), f=None, msg=str(res.message))\n",
    "            if len(self._cache) < self._cache_max:\n",
    "                self._cache[key] = val\n",
    "            if self.profile:\n",
    "                self._prof[\"total_s\"] += time.perf_counter() - t0\n",
    "            return val\n",
    "\n",
    "        t_val = float(res.fun)\n",
    "        if not return_f:\n",
    "            val = LPValue(ok=True, t=t_val, f=None, msg=\"OK\")\n",
    "            if len(self._cache) < self._cache_max:\n",
    "                self._cache[key] = val\n",
    "            if self.profile:\n",
    "                self._prof[\"total_s\"] += time.perf_counter() - t0\n",
    "            return val\n",
    "\n",
    "        x = res.x\n",
    "        f = x[: n * m].reshape((n, m))\n",
    "        val = LPValue(ok=True, t=t_val, f=f, msg=\"OK\")\n",
    "        if len(self._cache) < self._cache_max:\n",
    "            self._cache[key] = val\n",
    "        if self.profile:\n",
    "            self._prof[\"total_s\"] += time.perf_counter() - t0\n",
    "        return val\n",
    "\n",
    "    def print_profile(self, label: str = \"\"):\n",
    "        p = self._prof\n",
    "        calls = p[\"calls\"]\n",
    "        hits = p[\"cache_hits\"]\n",
    "        misses = calls - hits\n",
    "        head = f\"=== solve_lp profile {label} ===\".strip()\n",
    "        print(\"\\n\" + head)\n",
    "        print(f\"calls:      {calls}\")\n",
    "        print(f\"cache_hits: {hits} ({hits / max(1, calls):.1%})\")\n",
    "        print(f\"misses:     {misses} ({misses / max(1, calls):.1%})\")\n",
    "        print(f\"build_eq:   {p['build_eq_s']:.3f}s\")\n",
    "        print(f\"build_ub:   {p['build_ub_s']:.3f}s\")\n",
    "        print(f\"linprog:    {p['linprog_s']:.3f}s\")\n",
    "        print(f\"total:      {p['total_s']:.3f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Outer optimization (NO faces) with blocky + random starts\n",
    "# --------------------------\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    ok: bool\n",
    "    t: float\n",
    "    s: np.ndarray\n",
    "    msg: str\n",
    "\n",
    "\n",
    "def s_from_z_monotone(z: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Smooth monotone map R^n -> {1 >= s1 >= ... >= sn >= 0} without sorting.\n",
    "    s1 = sigmoid(z1)\n",
    "    si = s_{i-1} * sigmoid(zi)\n",
    "    \"\"\"\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    s = np.empty_like(z)\n",
    "    s[0] = sigmoid(z[0])\n",
    "    for i in range(1, z.size):\n",
    "        s[i] = s[i - 1] * sigmoid(z[i])\n",
    "    return s\n",
    "\n",
    "\n",
    "def z_from_s_monotone(s: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse-ish map for initialization:\n",
    "      z1 = logit(s1)\n",
    "      zi = logit(si / s_{i-1}) for i>=2\n",
    "    \"\"\"\n",
    "    s = np.clip(np.asarray(s, dtype=float), 1e-8, 1 - 1e-8)\n",
    "\n",
    "    def logit(u):\n",
    "        u = np.clip(u, 1e-8, 1 - 1e-8)\n",
    "        return np.log(u / (1 - u))\n",
    "\n",
    "    z = np.empty_like(s)\n",
    "    z[0] = logit(s[0])\n",
    "    for i in range(1, s.size):\n",
    "        ratio = s[i] / max(s[i - 1], 1e-12)\n",
    "        z[i] = logit(np.clip(ratio, 1e-8, 1 - 1e-8))\n",
    "    return z\n",
    "\n",
    "\n",
    "def blocky_seeds(n: int, rng: np.random.Generator) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate monotone, 'face-like' s vectors as STARTS (not constraints).\n",
    "    Includes:\n",
    "      - spike + flat tail: [1, u, ..., u]\n",
    "      - two-block / three-block step functions\n",
    "      - stick-breaking sharp drops\n",
    "    \"\"\"\n",
    "    seeds: list[np.ndarray] = []\n",
    "\n",
    "    # 1) Spike + flat tail\n",
    "    for u in np.linspace(0.02, 0.8, 25):\n",
    "        s = np.full(n, float(u))\n",
    "        s[0] = 1.0\n",
    "        seeds.append(s)\n",
    "\n",
    "    # 2) Slightly relaxed spike (helps smooth local methods)\n",
    "    for u in np.linspace(0.02, 0.8, 12):\n",
    "        for top in (0.98, 0.995, 0.999):\n",
    "            s = np.full(n, float(u))\n",
    "            s[0] = float(top)\n",
    "            seeds.append(s)\n",
    "\n",
    "    # 3) Two-block steps\n",
    "    for k in range(1, n):\n",
    "        for _ in range(10):\n",
    "            a = rng.uniform(0.6, 1.0)\n",
    "            b = rng.uniform(0.0, min(a, 0.7))\n",
    "            s = np.empty(n)\n",
    "            s[:k] = a\n",
    "            s[k:] = b\n",
    "            seeds.append(s)\n",
    "\n",
    "    # 4) Three-block steps\n",
    "    for _ in range(40):\n",
    "        k1 = int(rng.integers(1, n - 1))\n",
    "        k2 = int(rng.integers(1, n - k1))\n",
    "        a = rng.uniform(0.7, 1.0)\n",
    "        b = rng.uniform(0.15, min(a, 0.85))\n",
    "        c = rng.uniform(0.0, min(b, 0.6))\n",
    "        s = np.empty(n)\n",
    "        s[:k1] = a\n",
    "        s[k1:k1 + k2] = b\n",
    "        s[k1 + k2:] = c\n",
    "        seeds.append(s)\n",
    "\n",
    "    # 5) Stick-breaking monotone (often produces sharp drops)\n",
    "    for _ in range(60):\n",
    "        s = np.empty(n)\n",
    "        s[0] = rng.uniform(0.5, 1.0)\n",
    "        for i in range(1, n):\n",
    "            s[i] = s[i - 1] * rng.uniform(0.0, 1.0)\n",
    "        seeds.append(s)\n",
    "\n",
    "    return seeds\n",
    "\n",
    "\n",
    "def minimize_over_s_unconstrained(\n",
    "    solver: FullProgramLPSolver,\n",
    "    n_random: int = 300,\n",
    "    n_blocky_starts: int = 80,\n",
    "    n_random_starts: int = 12,\n",
    "    seed: int = 0,\n",
    "    local_method: str = \"Powell\",\n",
    "    maxiter: int = 600,\n",
    "    add_best_scan_start: bool = True,\n",
    ") -> SearchResult:\n",
    "    n = solver.n\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # --- phase 1: random scan in z-space -> monotone s ---\n",
    "    best_t = float(\"inf\")\n",
    "    best_s = None\n",
    "\n",
    "    for _ in range(n_random):\n",
    "        z = rng.normal(size=n)\n",
    "        s = s_from_z_monotone(z)\n",
    "        val = solver.solve_lp(s, return_f=False)\n",
    "        if val.ok and val.t < best_t:\n",
    "            best_t = val.t\n",
    "            best_s = s.copy()\n",
    "\n",
    "    if best_s is None:\n",
    "        best_s = np.full(n, 0.5, dtype=float)\n",
    "\n",
    "    # --- objective in z-space ---\n",
    "    def obj(z):\n",
    "        s = s_from_z_monotone(z)\n",
    "        val = solver.solve_lp(s, return_f=False)\n",
    "        return val.t if val.ok else 1e6\n",
    "\n",
    "    # --- build starts: (1) best from scan, (2) blocky, (3) random ---\n",
    "    starts: list[np.ndarray] = []\n",
    "\n",
    "    if add_best_scan_start:\n",
    "        starts.append(z_from_s_monotone(best_s))\n",
    "\n",
    "    # blocky starts (shuffle & cap)\n",
    "    bseeds = blocky_seeds(n, rng)\n",
    "    rng.shuffle(bseeds)\n",
    "    for s0 in bseeds[: max(0, n_blocky_starts)]:\n",
    "        starts.append(z_from_s_monotone(s0))\n",
    "\n",
    "    # random starts\n",
    "    for _ in range(max(0, n_random_starts)):\n",
    "        starts.append(rng.normal(size=n))\n",
    "\n",
    "    # --- local searches ---\n",
    "    best_z = None\n",
    "    best_local = best_t\n",
    "    best_msg = \"OK\"\n",
    "\n",
    "    for z0 in starts:\n",
    "        res = minimize(obj, z0, method=local_method, options={\"maxiter\": maxiter, \"disp\": False})\n",
    "        f = float(res.fun)\n",
    "        if f < best_local:\n",
    "            best_local = f\n",
    "            best_z = np.array(res.x, copy=True)\n",
    "\n",
    "    s_star = s_from_z_monotone(best_z) if best_z is not None else best_s\n",
    "    lp_star = solver.solve_lp(s_star, return_f=False)\n",
    "    return SearchResult(lp_star.ok, lp_star.t, s_star, lp_star.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Solving n=8, h=1, C=4.0\n",
      "\n",
      "RESULT (NO faces) n=8, h=1, C=4.0\n",
      "  t= 2.90938\n",
      "  s=[1.000000 0.272746 0.272746 0.272746 0.272746 0.272746 0.272746 0.272746]\n",
      "  ok=True, msg=OK\n",
      "\n",
      "=== solve_lp profile (n=8, h=1, C=4.0) ===\n",
      "calls:      50378\n",
      "cache_hits: 37137 (73.7%)\n",
      "misses:     13241 (26.3%)\n",
      "build_eq:   5.140s\n",
      "build_ub:   113.466s\n",
      "linprog:    316.363s\n",
      "total:      437.783s\n",
      "\n",
      "============================================================\n",
      "Solving n=8, h=2, C=4.0\n",
      "\n",
      "RESULT (NO faces) n=8, h=2, C=4.0\n",
      "  t= 2.48395\n",
      "  s=[1.000000 0.211963 0.211963 0.211963 0.211963 0.211963 0.211963 0.211963]\n",
      "  ok=True, msg=OK\n",
      "\n",
      "=== solve_lp profile (n=8, h=2, C=4.0) ===\n",
      "calls:      58752\n",
      "cache_hits: 43972 (74.8%)\n",
      "misses:     14780 (25.2%)\n",
      "build_eq:   5.779s\n",
      "build_ub:   236.609s\n",
      "linprog:    1367.260s\n",
      "total:      1612.906s\n",
      "\n",
      "============================================================\n",
      "Solving n=8, h=3, C=4.0\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "C = 4.0\n",
    "\n",
    "outer_kwargs = dict(\n",
    "    n_random=250,          # scan budget\n",
    "    n_blocky_starts=120,   # blocky starts help find face-like optima\n",
    "    n_random_starts=10,    # still include some random starts\n",
    "    seed=1,\n",
    "    local_method=\"Powell\",\n",
    "    maxiter=500,\n",
    ")\n",
    "\n",
    "for h in range(1, n):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Solving n={n}, h={h}, C={C}\")\n",
    "\n",
    "    solver = FullProgramLPSolver(\n",
    "        n=n,\n",
    "        h=h,\n",
    "        C=C,\n",
    "        cache_tol=1e-4,\n",
    "        cache_max=200_000,\n",
    "        profile=True,\n",
    "    )\n",
    "\n",
    "    res = minimize_over_s_unconstrained(solver, **outer_kwargs)\n",
    "\n",
    "    print(\n",
    "        f\"\\nRESULT (NO faces) n={n}, h={h}, C={C}\\n\"\n",
    "        f\"  t={res.t: .6g}\\n\"\n",
    "        f\"  s={np.array2string(res.s, precision=6, floatmode='fixed')}\\n\"\n",
    "        f\"  ok={res.ok}, msg={res.msg}\"\n",
    "    )\n",
    "\n",
    "    solver.print_profile(label=f\"(n={n}, h={h}, C={C})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocky_seeds(n: int, rng: np.random.Generator):\n",
    "    \"\"\"\n",
    "    Yield monotone 'face-like' s vectors as GOOD STARTS (not constraints).\n",
    "    Includes:\n",
    "      - [1, u, u, ..., u]  (your best h=4,n=6 case)\n",
    "      - 2-3 block step functions\n",
    "      - near-1 spike with flat tail\n",
    "    \"\"\"\n",
    "    seeds = []\n",
    "\n",
    "    # 1) Spike + flat tail: s = [1, u, ..., u]\n",
    "    for u in np.linspace(0.05, 0.8, 20):\n",
    "        s = np.full(n, u, dtype=float)\n",
    "        s[0] = 1.0\n",
    "        seeds.append(s)\n",
    "\n",
    "    # 2) Slightly relaxed spike (helps smooth optimizers)\n",
    "    for u in np.linspace(0.05, 0.8, 10):\n",
    "        for top in (0.98, 0.995, 0.999):\n",
    "            s = np.full(n, u, dtype=float)\n",
    "            s[0] = top\n",
    "            seeds.append(s)\n",
    "\n",
    "    # 3) Two-block step: [a,...,a, b,...,b] with a>=b\n",
    "    for k in range(1, n):  # split point\n",
    "        for _ in range(8):\n",
    "            a = rng.uniform(0.6, 1.0)\n",
    "            b = rng.uniform(0.0, min(a, 0.6))\n",
    "            s = np.empty(n)\n",
    "            s[:k] = a\n",
    "            s[k:] = b\n",
    "            seeds.append(s)\n",
    "\n",
    "    # 4) Three-block step: [a]*k1 + [b]*k2 + [c]*rest\n",
    "    for _ in range(30):\n",
    "        k1 = rng.integers(1, n-1)\n",
    "        k2 = rng.integers(1, n-k1)\n",
    "        a = rng.uniform(0.7, 1.0)\n",
    "        b = rng.uniform(0.2, min(a, 0.8))\n",
    "        c = rng.uniform(0.0, min(b, 0.5))\n",
    "        s = np.empty(n)\n",
    "        s[:k1] = a\n",
    "        s[k1:k1+k2] = b\n",
    "        s[k1+k2:] = c\n",
    "        seeds.append(s)\n",
    "\n",
    "    # 5) Random \"stick-breaking\" monotone (often produces sharp drops)\n",
    "    for _ in range(50):\n",
    "        s = np.empty(n)\n",
    "        s[0] = rng.uniform(0.5, 1.0)\n",
    "        for i in range(1, n):\n",
    "            s[i] = s[i-1] * rng.uniform(0.0, 1.0)\n",
    "        seeds.append(s)\n",
    "\n",
    "    return seeds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
